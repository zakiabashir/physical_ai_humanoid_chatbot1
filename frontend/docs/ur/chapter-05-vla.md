---
sidebar_position: 5
title: باب 5 - ویژن-لینگویج-ایکشن ماڈلز
---

# باب 5: ویژن-لینگویج-ایکشن ماڈلز

یہ باب ویژن-لینگویج-ایکشن (VLA) ماڈلز کو کور کرتا ہے، جو کہ روبوٹ کنٹرول کے لیے ایک ابھرتی ہوئی پیراڈائم ہے جو بصری پریکپشن، زبان کی سمجھ، اور ایکشن جنریشن کو ملاتی ہے۔

## 5.1 VLA ماڈلز کیا ہیں؟

VLA ماڈلز بصری اور زبانی ان پٹس لیتی ہیں اور براہ راست روبوٹ ایکشنز آؤٹ پٹ کرتے ہیں۔

| روایتی پائپ لائن | VLA ماڈل |
|---------------------|-----------|
| الگ algod modules | ایک متحدہ ماڈل |
| ہاتھ سے ڈیزائن شدہ فیچرز | سیکھا ہوا فیچرز |
| تبدیلیوں کے لیے زیڑ کا مضبوط | بہتر generalizes کرتا ہے |

## 5.2 VLA آرکائیکچر

## 5.3 اوپن VLA

## 5.4 VLA ماڈلز ٹریننگ

## 5.5 VLA ماڈلز فائن ٹیوننگ

## 5.6 مختلف روبوٹ اقسام کے لیے VLA

### منپولیشن

### نیویگیشن

## 5.7 VLA ماڈلز کے ساتھ چیلنجز

| چیلنج | حل |
|-----------|----------|
| **ڈیٹاEFFICIENCY** | بڑے ڈیٹا سیٹس پر پری-ٹریننگ، sim-to-real |
| **جنرلائزیشن** | Domain رینڈمائزیشن، multi-task ٹریننگ |
| **حفاظت** | Constrainڈ ڈیکوڈنگ، ایکشن اسموتھنگ |
| **ریل ٹایم** | ماڈل ڈسٹلریشن، kwantization |
| **Sim-to-real gap** | اصل ڈیٹا پر fine-tuning |

## 5.8 VLA کے لیے مفت وسائل

| وسائل | وضاحت | لنک |
|----------|-------------|------|
| **OpenVLA** | اوپن سورس VLA ماڈل | github.com/openvla/openvla |
| **BridgeData** | روبوٹ منپولیشن ڈیٹا سیٹ | rail.berkeley.edu/bridgedata |
| **RT-1** | روبوٹکس ٹرانسفارمر | github.com/google-research/robotics_transformer1 |
| **RT-2** | روبوٹکس ٹرانسفارمر 2 | github.com/google-research/robotics_transformer2 |

## خلاصہ

اس باب میں، آپ نے سیکھا:

- **VLA ماڈلز** ویژن، لینگویج، اور ایکشن کو ایک ماڈل میں ملاتے ہیں
- **End-to-end** لرننگ روایتی روبوٹکس پائپ لائنز کو بدل دیتا ہے
- **OpenVLA** ایک اوپن سورس عمل ہے
- **فائن ٹیوننگ** ماڈلز کو مخصوص روبوٹس کے لیے adapt کرتا ہے
- **چیلنجز** میں ڈیٹاEFFICIENCY، حفاظت، اور جنرلائزیشن شامل ہیں

## اگلا قدم

**[باب 6: کیپ اسٹون پروجیکٹ](./chapter-06-capstone.md)** پر جاری رکھیں تاکہ اپنا مکمل انسان نما روبوٹ سسٹم بنائیں۔
